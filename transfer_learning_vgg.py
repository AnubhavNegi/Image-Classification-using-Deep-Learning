{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\n\nimg_h = 224\nimg_w = 224\nbatch_sz = 32\n\ntrain_datagen = ImageDataGenerator(\n                                    preprocessing_function=preprocess_input,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    validation_split=0.2\n                                  )\n\n\ntrain = train_datagen.flow_from_directory('../input/food41/images',\n                                              target_size=(img_h, img_w),\n                                              class_mode='categorical',\n                                              batch_size=batch_sz,\n                                              subset='training'\n                                        )\n\nval = train_datagen.flow_from_directory('../input/food41/images',\n                                           target_size=(img_h, img_w),\n                                           class_mode='categorical',\n                                           batch_size=batch_sz,\n                                           subset='validation'\n                                       )\n\nVGG_base = VGG16()\nmodel=models.Sequential()\nfor layer in VGG_base.layers[:-3]:\n    model.add(layer)\nfor layer in model.layers[:-16]:\n    layer.trainable=False\nmodel.add(layers.Dense(units=4096, activation='relu'))\nmodel.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(units=4096, activation='relu'))\nmodel.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(units=101, activation='softmax'))\n\n\nmodel.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\nhist = model.fit(x=train,\n                 validation_data=val,\n                 epochs=15,\n                 verbose=1)\n\nmodel.save('./food.h5')\n\nacc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nepochs = list(range(len(acc)))\nplt.plot(epochs, acc, 'b', label = 'Training Accuracy')\nplt.plot(epochs, val_acc, 'g', label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc = 'upper left')\nplt.savefig('./t_acc.png')\nplt.figure()\n\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\nepochs = list(range(len(loss)))\nplt.plot(epochs, loss, 'b', label = 'Training loss')\nplt.plot(epochs, val_loss, 'g', label = 'Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(loc = 'upper left')\nplt.savefig('./v_acc.png')\nplt.show()","metadata":{"_uuid":"fc92dd29-f339-4c2b-b35c-01e07bdebadf","_cell_guid":"9381e6f8-cad5-4710-a3a6-4fc9d0262d55","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}